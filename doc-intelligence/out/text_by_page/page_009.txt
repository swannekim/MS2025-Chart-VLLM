using human written instructions capturing varied
nuances present in charts. We also aim to propose a
more generalized benchmark catered to addressing
complex visual elements in charts with more chart
relevant evaluation metrics.
Limitations
Despite the effectiveness of our instruction-tuning
approach and our model, there are notable limita-
tions. Firstly, the instruction-tuning data is gen-
erated using a proprietary LLM, which could re-
strict the model's use in certain commercial envi-
ronments. Secondly, the input resolution of our
model's vision encoder is capped at 448x448; any
increase in resolution leads to a quadratic rise in
processing time. Third, we depend on the closed-
source model, GPT4, for evaluating crucial metrics
such as Informativeness and Factual Correctness.
The frequent updates and potential deprecation of
closed-source models pose challenges for the repro-
ducibility of our results. Lastly, the model is prone
to hallucinations, occasionally producing factually
incorrect statements or erroneous code. We advise
users to implement robust guardrails and exercise
caution when deploying our model in real-world
applications.
Ethics Statement
Since our model generates responses autoregres-
sively, it is prone to errors and hallucinations. The
outputs can sometimes be misleading or contain
inaccuracies. Additionally, there is no guarantee
that the codes generated by our model will be free
from malicious content. Therefore, it is crucial
for users of our model to implement strict safety
guidelines to mitigate these potential risks. How-
ever, the base datasets we use for further generating
our instruction-tuning data are available publicly
either as full datasets or URLs with public licenses.
Furthermore, all chart images in our dataset were
sourced from existing, publicly available research
papers that have filtered out any offensive content.
We plan to release our visual instruction-tuning
dataset in the same way as the base datasets (images
where the licenses allow us and URLs where they
do not). We also release our trained ChartGemma
model in easy-to-use demos and various formats
and across quantizations for extremely accessible
adoption by the community. For our human evalu-
ation study, we requested the help of our research
collaborators. There were no personal identifica-
tion information collected during this study. As the
focus of the research was about assessing models'
capabilities and limitations in several chart under-
standing tasks, the human evaluation performed
by the authors does not add any ethical issues or
unwanted biases.
Acknowledgements
This research was supported by the Natural Sci-
ences & Engineering Research Council (NSERC)
of Canada and Canada Foundation for Innovation
(CFI). The authors acknowledge the computational
resources provided by the Digital Research Al-
liance of Canada.
References
Mubashara Akhtar, Oana Cocarascu, and Elena Simperl.
2023a. Reading and reasoning over chart images
for evidence-based automated fact-checking. arXiv
preprint arXiv:2301.11843.
Mubashara Akhtar, Oana Cocarascu, and Elena Sim-
perl. 2023b. Reading and reasoning over chart im-
ages for evidence-based automated fact-checking. In
Findings of the Association for Computational Lin-
guistics: EACL 2023, pages 399-414, Dubrovnik,
Croatia. Association for Computational Linguistics.
Mubashara Akhtar, Nikesh Subedi, Vivek Gupta, Sa-
har Tahmasebi, Oana Cocarascu, and Elena Sim-
perl. 2023c. Chartcheck: An evidence-based fact-
checking dataset over real-world chart images. arXiv
preprint arXiv: 2311.07453.
Alpaca. 2023. Alpaca. https://crfm.stanford.
edu/2023/03/13/alpaca.html.
Lucas Beyer, Andreas Steiner, André Susano Pinto,
Alexander Kolesnikov, Xiao Wang, Daniel Salz,
Maxim Neumann, Ibrahim Alabdulmohsin, Michael
Tschannen, Emanuele Bugliarello, Thomas Un-
terthiner, Daniel Keysers, Skanda Koppula, Fangyu
Liu, Adam Grycner, Alexey Gritsenko, Neil Houlsby,
Manoj Kumar, Keran Rong, Julian Eisenschlos,
Rishabh Kabra, Matthias Bauer, Matko Bošn-
jak, Xi Chen, Matthias Minderer, Paul Voigtlaen-
der, Ioana Bica, Ivana Balazevic, Joan Puigcerver,
Pinelopi Papalampidi, Olivier Henaff, Xi Xiong,
Radu Soricut, Jeremiah Harmsen, and Xiaohua Zhai.
2024. PaliGemma: A versatile 3B VLM for transfer.
arXiv preprint arXiv:2407.07726.
Chris Callison-Burch, Miles Osborne, and Philipp
Koehn. 2006. Re-evaluating the role of Bleu in ma-
chine translation research. In 11th Conference of
the European Chapter of the Association for Com-
putational Linguistics, pages 249-256, Trento, Italy.
Association for Computational Linguistics.