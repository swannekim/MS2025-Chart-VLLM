{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## conda virtualenv ÏÉùÏÑ±\n",
        "- Python 3.13.1ÏùÄ AzureMLÏùò ÏùºÎ∂Ä Ï¢ÖÏÜçÏÑ±ÏóêÏÑú Î¨∏Ï†ú Î∞úÏÉù. (Ï∞∏Í≥†: https://docs.ultralytics.com/ko/guides/azureml-quickstart/#quickstart-from-terminal)\n",
        "- ÌååÏùº Í≤ΩÎ°ú: Users/t-yooyeunkim/ultralytics-yolo/yolo11.ipynb\n",
        "```bash\n",
        "conda create --name yolo11env -y python=3.12\n",
        "conda activate yolo11env # conda deactivate\n",
        "conda install pip -y\n",
        "```\n",
        "```bash\n",
        "pip install ipykernel\n",
        "python -m ipykernel install --user --name=yolo11env --display-name \"Python (yolo11env)\"\n",
        "```\n",
        "- Jupyter ÏÉÅÎã® Î©îÎâ¥ ‚Üí Kernel ‚Üí Change Kernel ‚Üí Python (yolo11env) ÏÑ†ÌÉù\n",
        "```bash\n",
        "cd ultralytics\n",
        "pip install -r requirements.txt\n",
        "pip install ultralytics\n",
        "pip install onnx\n",
        "pip install opencv-python\n",
        "pip install matplotlib\n",
        "pip install azure-ai-ml\n",
        "pip install azureml.fsspec\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1755794875178
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/yolo11env/bin/python\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## GPU Î∞è Î™®Îç∏ ÏûëÏóÖÏàòÌñâ ÌôïÏù∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1755794892737
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch CUDA: True CUDA device: NVIDIA H100 NVL\n",
            "Linux-6.8.0-1030-azure-x86_64-with-glibc2.35\n"
          ]
        }
      ],
      "source": [
        "import torch, platform\n",
        "print(\"Torch CUDA:\", torch.cuda.is_available(), \"CUDA device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)\n",
        "print(platform.platform())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "```bash\n",
        "yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'\n",
        "```\n",
        "```bash\n",
        "(yolo11env) azureuser@standard-nc40ads-h100-v5:/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo$ yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'\n",
        "WARNING ‚ö†Ô∏è user config directory '/home/azureuser/.config/Ultralytics' is not writeable, defaulting to '/tmp' or CWD. Alternatively you can define a YOLO_CONFIG_DIR environment variable for this path.\n",
        "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 54.2MB/s]\n",
        "Ultralytics 8.3.182 üöÄ Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA H100 NVL, 95248MiB)\n",
        "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
        "\n",
        "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 134k/134k [00:00<00:00, 4.35MB/s]\n",
        "image 1/1 /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/bus.jpg: 640x480 4 persons, 1 bus, 55.4ms\n",
        "Speed: 5.2ms preprocess, 55.4ms inference, 131.4ms postprocess per image at shape (1, 3, 640, 480)\n",
        "Results saved to runs/detect/predict\n",
        "üí° Learn more at https://docs.ultralytics.com/modes/predict\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## ÌòÑÏû¨ ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨ ÌôïÏù∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1755794893010
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## data Ìè¥Îçî ÏÉùÏÑ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1755794899489
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CWD: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo\n",
            "‚úÖ made folders under ./ultralytics-yolo/data/...\n",
            "train chart: 0 nonchart: 0\n",
            "val chart: 0 nonchart: 0\n",
            "test chart: 0 nonchart: 0\n"
          ]
        }
      ],
      "source": [
        "# 1) ÎÖ∏Ìä∏Î∂Å Ìè¥ÎçîÎ°ú Ïù¥Îèô\n",
        "import os, pathlib\n",
        "os.chdir(\"ultralytics-yolo\")  # ÌòÑÏû¨ CWD Í∏∞Ï§Ä ÌïòÏúÑ Ìè¥ÎçîÎ°ú Ïù¥Îèô\n",
        "print(\"CWD:\", os.getcwd())\n",
        "\n",
        "# 2) data/ ÎºàÎåÄ ÎßåÎì§Í∏∞\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    for cls in [\"chart\",\"nonchart\"]:\n",
        "        pathlib.Path(f\"data/{split}/{cls}\").mkdir(parents=True, exist_ok=True)\n",
        "print(\"‚úÖ made folders under ./ultralytics-yolo/data/...\")\n",
        "\n",
        "# 3) ÏÉòÌîå Í∞úÏàò ÌôïÏù∏ Ìï®Ïàò\n",
        "def count_images(p):\n",
        "    return sum(len(files) for _,_,files in os.walk(p))\n",
        "\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    print(split, \"chart:\", count_images(f\"data/{split}/chart\"),\n",
        "                 \"nonchart:\", count_images(f\"data/{split}/nonchart\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Îç∞Ïù¥ÌÑ∞ Ïù¥ÎØ∏ÏßÄÌååÏùº Ï±ÑÏö∞Í∏∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1755794915795
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASE: LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset\n",
            "ROOT: ['LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/test/', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/val/']\n",
            "SAMPLE: ['LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/png/00006834003065.png', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/png/00035547003867.png', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/png/00035547003876.png', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/png/00097754005965.png', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/png/00108924005661.png']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding of current TracerProvider is not allowed\n",
            "Overriding of current LoggerProvider is not allowed\n",
            "Overriding of current MeterProvider is not allowed\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n"
          ]
        }
      ],
      "source": [
        "from azureml.fsspec import AzureMachineLearningFileSystem as AMLFS\n",
        "import os, pathlib\n",
        "\n",
        "# blobstore Í≤ΩÎ°ú\n",
        "BLOB_PREFIX = \"azureml://subscriptions/0feccff1-79cf-4ed1-b4c9-020c3ec2383b/resourcegroups/chartvllm-rg/workspaces/chartvllm-workspace/datastores/workspaceblobstore/paths/LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/\"\n",
        "\n",
        "fs = AMLFS(BLOB_PREFIX)  # Ïù∏Ï¶ùÏùÄ CIÏóêÏÑú ÏûêÎèôÏúºÎ°ú Î∂ôÏùå (ÏõåÌÅ¨Ïä§ÌéòÏù¥Ïä§ Í∂åÌïú ÌïÑÏöî)\n",
        "\n",
        "# BASE: datastore Í∏∞Ï§Ä Ï†àÎåÄ Í≤ΩÎ°ú(ChartQA-DatasetÍπåÏßÄ Ìè¨Ìï®)\n",
        "BASE = BLOB_PREFIX.split(\"/paths/\")[1].strip(\"/\")  # 'LocalUpload/.../ChartQA-Dataset'\n",
        "print(\"BASE:\", BASE)\n",
        "\n",
        "print(\"ROOT:\", fs.ls(BASE)[:5])                 # ['.../ChartQA-Dataset/train/', ...]: ['train/', 'val/', 'test/'] ÏãùÏúºÎ°ú Îñ†Ïïº Ï†ïÏÉÅ\n",
        "print(\"SAMPLE:\", fs.ls(f\"{BASE}/train/png\")[:5])  # Ïù¥ÎØ∏ÏßÄ Î™©Î°ùÏù¥ ÎÇòÏôÄÏïº Ï†ïÏÉÅ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### chart data: Îç∞Ïù¥ÌÑ∞ ÏûëÏóÖ > ÌÉëÏû¨ > ÏÇ¨Ïö©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1755795011239
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mount contains: [PosixPath('/home/azureuser/cloudfiles/data/uri/chartqa_dataset/test'), PosixPath('/home/azureuser/cloudfiles/data/uri/chartqa_dataset/train'), PosixPath('/home/azureuser/cloudfiles/data/uri/chartqa_dataset/val')]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "MOUNT = Path(\"/home/azureuser/cloudfiles/data/uri/chartqa_dataset\")  # StudioÍ∞Ä ÌÉëÏû¨Ìïú Í≤ΩÎ°ú\n",
        "print(\"mount contains:\", list(MOUNT.iterdir()))  # ['train','val','test'] ÌôïÏù∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1755795021238
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: linked data/train/chart -> /home/azureuser/cloudfiles/data/uri/chartqa_dataset/train/png\n",
            "val: linked data/val/chart -> /home/azureuser/cloudfiles/data/uri/chartqa_dataset/val/png\n",
            "test: linked data/test/chart -> /home/azureuser/cloudfiles/data/uri/chartqa_dataset/test/png\n"
          ]
        }
      ],
      "source": [
        "# data/{split}/chart Î•º 'Ìè¥Îçî ÎßÅÌÅ¨'Î°ú ÍµêÏ≤¥\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    src_dir = MOUNT / split / \"png\"          # ÏõêÎ≥∏ Ï∞®Ìä∏ Ïù¥ÎØ∏ÏßÄ Ìè¥Îçî\n",
        "    dst_root = Path(\"data\") / split\n",
        "    dst_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    link = dst_root / \"chart\"\n",
        "    if link.exists() or link.is_symlink():\n",
        "        if link.is_dir() and not link.is_symlink():\n",
        "            # Í∏∞Ï°¥Ïóê Î≥µÏÇ¨Ìïú Í≤å ÏûàÏúºÎ©¥ Î∞±ÏóÖ/ÏÇ≠Ï†ú ÌÉù1\n",
        "            os.system(f\"rm -rf '{link}'\")    # ÌïÑÏöî Ïãú ÏïàÏ†ÑÌïòÍ≤å Î∞±ÏóÖ ÌõÑ ÏÇ≠Ï†ú\n",
        "        else:\n",
        "            link.unlink()\n",
        "    os.symlink(src_dir, link)                # ‚úÖ Ìè¥Îçî Ï†ÑÏ≤¥Î•º ÎßÅÌÅ¨ (Ï¶âÏãú ÎÅù)\n",
        "    print(f\"{split}: linked {link} -> {src_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1755795035501
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train chart: 18317 nonchart: 0\n",
            "val chart: 1056 nonchart: 0\n",
            "test chart: 1509 nonchart: 0\n"
          ]
        }
      ],
      "source": [
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    print(split, \"chart:\", count_images(f\"data/{split}/chart\"),\n",
        "                 \"nonchart:\", count_images(f\"data/{split}/nonchart\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### nonchart data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1755795621210
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/yolo11env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading split 'validation' to '_foz_cache/coco-2017/validation' if necessary\n",
            "Downloading annotations to '_foz_cache/coco-2017/tmp-download/annotations_trainval2017.zip'\n",
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|    1.9Gb/1.9Gb [5.2s elapsed, 0s remaining, 401.4Mb/s]       \n",
            "Extracting annotations to '_foz_cache/coco-2017/raw/instances_val2017.json'\n",
            "Downloading 5000 images\n",
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [1.5m elapsed, 0s remaining, 54.0 images/s]      \n",
            "Writing annotations to '_foz_cache/coco-2017/validation/labels.json'\n",
            "Dataset info written to '_foz_cache/coco-2017/info.json'\n",
            "Deleting existing dataset 'coco_val_5k'\n",
            "Loading 'coco-2017' split 'validation'\n",
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [836.3ms elapsed, 0s remaining, 6.0K samples/s]      \n",
            "Dataset 'coco_val_5k' created\n",
            "train nonchart: 3500 (symlink: 3500 copy: 0 )\n",
            "val   nonchart: 750 (symlink: 750 copy: 0 )\n",
            "test  nonchart: 750 (symlink: 750 copy: 0 )\n",
            "train chart: 18317 nonchart: 3500\n",
            "val chart: 1056 nonchart: 750\n",
            "test chart: 1509 nonchart: 750\n"
          ]
        }
      ],
      "source": [
        "# === COCO 2017 val(5K) ‚Üí data/{train,val,test}/nonchart Ï±ÑÏö∞Í∏∞ ===\n",
        "# - 5,000Ïû• Ï†ÑÎ∂Ä ÏÇ¨Ïö©\n",
        "# - Î∂ÑÎ∞∞: 70%/15%/15% = 3500 / 750 / 750\n",
        "# - symlink Ïö∞ÏÑ†, Ïã§Ìå® Ïãú copy Ìè¥Î∞±\n",
        "\n",
        "import os, shutil, random\n",
        "from pathlib import Path\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "# 0) Î™©Ìëú Í∞úÏàò(Í≥†Ï†ï 5k Î∂ÑÌï†)\n",
        "TARGET = {\"train\": 3500, \"val\": 750, \"test\": 750}\n",
        "\n",
        "# 1) dataset zoo Ï∫êÏãú(Ïû¨Ïã§Ìñâ Ïãú Ïû¨Îã§Ïö¥Î°úÎìú Î∞©ÏßÄ)\n",
        "fo.config.dataset_zoo_dir = \"_foz_cache\"\n",
        "Path(fo.config.dataset_zoo_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2) COCO 2017 validation 5k Î°úÎìú(Ï†ÑÏ≤¥)\n",
        "# ds = foz.load_zoo_dataset(\n",
        "#     \"coco-2017\",\n",
        "#     split=\"validation\",\n",
        "#     max_samples=5000,\n",
        "#     shuffle=True,\n",
        "#     dataset_dir=\"_foz_cache/coco_val_5k\",\n",
        "#     drop_existing_dataset=True,\n",
        "# )\n",
        "\n",
        "# ‚úÖ dataset_dir Ï†úÍ±∞, dataset_name ÏÇ¨Ïö©, ÎùºÎ≤® ÎØ∏Î°úÎî©\n",
        "ds = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",\n",
        "    max_samples=5000,\n",
        "    shuffle=True,\n",
        "    dataset_name=\"coco_val_5k\",\n",
        "    drop_existing_dataset=True,\n",
        "    label_types=[],          # ‚Üê annotation ÎØ∏Î°úÎî© (Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°úÎßå)\n",
        ")\n",
        "\n",
        "paths = ds.values(\"filepath\")\n",
        "random.seed(42)\n",
        "random.shuffle(paths)\n",
        "\n",
        "# 3) 70/15/15 Î∂ÑÌï†\n",
        "train_paths = paths[:TARGET[\"train\"]]\n",
        "val_paths   = paths[TARGET[\"train\"]:TARGET[\"train\"]+TARGET[\"val\"]]\n",
        "test_paths  = paths[TARGET[\"train\"]+TARGET[\"val\"]:TARGET[\"train\"]+TARGET[\"val\"]+TARGET[\"test\"]]\n",
        "\n",
        "def place(paths, dst_dir, prefer_symlink=True):\n",
        "    dst = Path(dst_dir); dst.mkdir(parents=True, exist_ok=True)\n",
        "    ln = cp = 0\n",
        "    for src in paths:\n",
        "        src = Path(src)\n",
        "        out = dst / src.name\n",
        "        if out.exists():  # Ï§ëÎ≥µ Î∞©ÏßÄ\n",
        "            continue\n",
        "        if prefer_symlink:\n",
        "            try:\n",
        "                os.symlink(src, out)  # Í∞ÄÏû• Îπ†Î¶Ñ\n",
        "                ln += 1\n",
        "                continue\n",
        "            except Exception:\n",
        "                pass\n",
        "        shutil.copy2(src, out)        # Ìè¥Î∞±\n",
        "        cp += 1\n",
        "    return ln, cp\n",
        "\n",
        "# 4) Ïã§Ï†ú Î∞∞Ïπò\n",
        "ln, cp = place(train_paths, \"data/train/nonchart\"); print(\"train nonchart:\", len(train_paths), \"(symlink:\", ln, \"copy:\", cp, \")\")\n",
        "ln, cp = place(val_paths,   \"data/val/nonchart\");   print(\"val   nonchart:\", len(val_paths),   \"(symlink:\", ln, \"copy:\", cp, \")\")\n",
        "ln, cp = place(test_paths,  \"data/test/nonchart\");  print(\"test  nonchart:\", len(test_paths),  \"(symlink:\", ln, \"copy:\", cp, \")\")\n",
        "\n",
        "# 5) ÏµúÏ¢Ö Í∞úÏàò ÌôïÏù∏\n",
        "def count_images(p): \n",
        "    p = Path(p)\n",
        "    return sum(1 for x in p.glob(\"*\") if x.suffix.lower() in {\".jpg\",\".jpeg\",\".png\",\".webp\"})\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    print(split, \"chart:\", count_images(f\"data/{split}/chart\"),\n",
        "                 \"nonchart:\", count_images(f\"data/{split}/nonchart\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1755796201130
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "target(chart): {'train': 18317, 'val': 1056, 'test': 1509} \n",
            "current(nonchart): {'train': 3500, 'val': 750, 'test': 750} \n",
            "need: {'train': 14817, 'val': 306, 'test': 759}\n",
            "[train] +2000 saved (total 2000/14817)\n",
            "[train] +2000 saved (total 4000/14817)\n",
            "[train] +2000 saved (total 6000/14817)\n",
            "[train] +2000 saved (total 8000/14817)\n",
            "[train] +2000 saved (total 10000/14817)\n",
            "[train] +2000 saved (total 12000/14817)\n",
            "[train] +2000 saved (total 14000/14817)\n",
            "[train] +817 saved (total 14817/14817)\n",
            "[train] done. saved_total=14817, out=data/train/nonchart\n",
            "[val] +306 saved (total 306/306)\n",
            "[val] done. saved_total=306, out=data/val/nonchart\n",
            "[test] +759 saved (total 759/759)\n",
            "[test] done. saved_total=759, out=data/test/nonchart\n",
            "train chart: 18317 nonchart: 18317\n",
            "val chart: 1056 nonchart: 1056\n",
            "test chart: 1509 nonchart: 1509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train save batch#0 (0/14817): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:38<00:00, 52.52it/s]\n",
            "train save batch#3 (6000/14817): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:37<00:00, 52.69it/s]HTTP Error 504 thrown while requesting GET https://huggingface.co/datasets/ds4sd/DocLayNet-v1.2/resolve/0daf93102e2efce76c3e11a274a5e0d0969391d3/data/train-00010-of-00072.parquet\n",
            "Retrying in 1s [Retry 1/5].\n",
            "train save batch#4 (8000/14817): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:35<00:00, 56.36it/s]\n",
            "train save batch#5 (10000/14817): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:38<00:00, 51.39it/s]\n",
            "train save batch#6 (12000/14817): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:40<00:00, 49.37it/s]\n",
            "train save batch#7 (14000/14817):  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 807/817 [00:21<00:00, 34.92it/s]\rtest save batch#0 (0/759):  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 755/759 [00:21<00:00, 30.32it/s]"
          ]
        }
      ],
      "source": [
        "# DocLayNet ‚Üí nonchart (streaming=True + Î≥ëÎ†¨ Ï†ÄÏû• + Ïû¨Ïã§Ìñâ ÏïàÏ†Ñ)\n",
        "%pip -q install datasets pillow tqdm\n",
        "\n",
        "import os, itertools, random\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from PIL import Image\n",
        "\n",
        "BASE    = Path(\"data\")\n",
        "SPLITS  = [\"train\",\"val\",\"test\"]\n",
        "SPLIT_MAP = {\"val\": \"validation\"}     # DocLayNet Î∂ÑÌï†Î™Ö Îß§Ìïë\n",
        "WORKERS = 32        # CI ÏΩîÏñ¥Ïóê ÎßûÏ∂∞ Ï°∞Ï†ï\n",
        "CHUNK   = 2000      # Ìïú Î≤àÏóê Î∞õÏïÑ Ï†ÄÏû•Ìï† ÏÉòÌîå Ïàò(Î©îÎ™®Î¶¨/ÎîîÏä§ÌÅ¨ Ïó¨Ïú†Ïóê ÎßûÍ≤å)\n",
        "\n",
        "# Ï†ÄÏû• Ìè¨Îß∑: 'png' ÎòêÎäî 'jpeg' (jpegÍ∞Ä ÎîîÏä§ÌÅ¨ Ìõ®Ïî¨ Ï†àÏïΩ)\n",
        "SAVE_FMT = \"png\"    # ÌïÑÏöîÌïòÎ©¥ 'jpeg' Î°ú Î≥ÄÍ≤Ω\n",
        "JPEG_QUALITY = 90\n",
        "\n",
        "def count_images(dirpath: Path):\n",
        "    exts = {\".png\",\".jpg\",\".jpeg\",\".webp\"}\n",
        "    return sum(1 for p in dirpath.glob(\"*\") if p.suffix.lower() in exts)\n",
        "\n",
        "# ÌòÑÏû¨ chart/nonchart Í∞úÏàò ‚Üí Î∂ÄÏ°±Î∂Ñ Í≥ÑÏÇ∞(Ï∞®Ìä∏ÏôÄ ÎèôÏàò ÎßûÏ∂îÍ∏∞)\n",
        "target  = {s: count_images(BASE/s/\"chart\")    for s in SPLITS}\n",
        "current = {s: count_images(BASE/s/\"nonchart\") for s in SPLITS}\n",
        "need    = {s: max(0, target[s]-current[s])    for s in SPLITS}\n",
        "print(\"target(chart):\", target, \"\\ncurrent(nonchart):\", current, \"\\nneed:\", need)\n",
        "\n",
        "def _dst_path(out_dir: Path, idx: int):\n",
        "    ext = \".jpg\" if SAVE_FMT == \"jpeg\" else \".png\"\n",
        "    return out_dir / f\"doclaynet_{idx:07d}{ext}\"\n",
        "\n",
        "def save_one(out_dir: Path, idx: int, pil_img: Image.Image):\n",
        "    dst = _dst_path(out_dir, idx)\n",
        "    if dst.exists():\n",
        "        return \"skip\"\n",
        "    if SAVE_FMT == \"jpeg\":\n",
        "        pil_img.convert(\"RGB\").save(dst, format=\"JPEG\", quality=JPEG_QUALITY, optimize=True)\n",
        "    else:\n",
        "        pil_img.save(dst)  # PNG\n",
        "    return \"save\"\n",
        "\n",
        "def fill_streaming(split: str, remaining: int, workers: int = WORKERS, chunk: int = CHUNK):\n",
        "    if remaining <= 0:\n",
        "        print(f\"[{split}] already balanced\")\n",
        "        return\n",
        "    hf_split = SPLIT_MAP.get(split, split)  # 'val' -> 'validation'\n",
        "    out_dir = BASE/split/\"nonchart\"; out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Ïä§Ìä∏Î¶¨Î∞ç Îç∞Ïù¥ÌÑ∞ÏÖã(Ï∫êÏãú ÌÅ¨Í≤å Ïïà ÏîÄ)\n",
        "    ds = load_dataset(\"ds4sd/DocLayNet-v1.2\", split=hf_split, streaming=True)\n",
        "    it = iter(ds)\n",
        "\n",
        "    saved_total = 0\n",
        "    idx_base = count_images(out_dir)  # ÎåÄÎûµÏ†Å ÏãúÏûë Ïù∏Îç±Ïä§(Ï∂©Îèå ÏòàÎ∞©Ïö©)\n",
        "    batch_no = 0\n",
        "\n",
        "    while saved_total < remaining:\n",
        "        k = min(chunk, remaining - saved_total)\n",
        "        batch = list(itertools.islice(it, k))\n",
        "        if not batch:\n",
        "            print(f\"[{split}] DocLayNet Í≥†Í∞à: {saved_total}/{remaining} Ï†ÄÏû• ÌõÑ Ï§ëÎã®\")\n",
        "            break\n",
        "\n",
        "        def task(en):\n",
        "            i, ex = en\n",
        "            return save_one(out_dir, idx_base + saved_total + i, ex[\"image\"])\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=workers) as pool:\n",
        "            futures = [pool.submit(task, (i, ex)) for i, ex in enumerate(batch)]\n",
        "            for _ in tqdm(as_completed(futures), total=len(futures),\n",
        "                          desc=f\"{split} save batch#{batch_no} ({saved_total}/{remaining})\"):\n",
        "                pass\n",
        "\n",
        "        # Ï†ÄÏû•/Ïä§ÌÇµ ÏßëÍ≥Ñ\n",
        "        saves = sum(1 for f in futures if f.result() == \"save\")\n",
        "        saved_total += saves\n",
        "        batch_no += 1\n",
        "        print(f\"[{split}] +{saves} saved (total {saved_total}/{remaining})\")\n",
        "\n",
        "    print(f\"[{split}] done. saved_total={saved_total}, out={out_dir}\")\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "for s in SPLITS:\n",
        "    fill_streaming(s, need[s], workers=WORKERS, chunk=CHUNK)\n",
        "\n",
        "# ÏµúÏ¢Ö Í∞úÏàò ÌôïÏù∏\n",
        "for s in SPLITS:\n",
        "    print(s, \"chart:\", count_images(BASE/s/\"chart\"),\n",
        "             \"nonchart:\", count_images(BASE/s/\"nonchart\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1755796201773
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train chart: 18317 nonchart: 18317\n",
            "val chart: 1056 nonchart: 1056\n",
            "test chart: 1509 nonchart: 1509\n"
          ]
        }
      ],
      "source": [
        "# ÏµúÏ¢Ö Í∞úÏàò ÌôïÏù∏\n",
        "def count_images(p): \n",
        "    p = Path(p)\n",
        "    return sum(1 for x in p.glob(\"*\") if x.suffix.lower() in {\".jpg\",\".jpeg\",\".png\",\".webp\"})\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    print(split, \"chart:\", count_images(f\"data/{split}/chart\"),\n",
        "                 \"nonchart:\", count_images(f\"data/{split}/nonchart\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1755791792723
        }
      },
      "outputs": [],
      "source": [
        "# # DocLayNet ‚Üí nonchart (ÎßÅÌÅ¨ Ïö∞ÏÑ†, Î≥ëÎ†¨ Ï†ÄÏû• X ‚Üí Í±∞Ïùò Ï¶âÏãú)\n",
        "# import os, random\n",
        "# from pathlib import Path\n",
        "# from datasets import load_dataset\n",
        "\n",
        "# BASE = Path(\"data\")\n",
        "# SPLITS = [\"train\",\"val\",\"test\"]\n",
        "\n",
        "# # 1) ÏßÄÍ∏à nonchart Í∞úÏàòÏôÄ chart Í∞úÏàòÎ•º ÏùΩÏñ¥ Î™©ÌëúÏπò ÏÇ∞Ï†ï(Ï∞®Ìä∏ÏôÄ Í∑†Ìòï ÎßûÏ∂îÍ∏∞)\n",
        "# def count_images(p: Path):\n",
        "#     exts = {\".png\",\".jpg\",\".jpeg\",\".webp\"}\n",
        "#     return sum(1 for x in p.glob(\"*\") if x.suffix.lower() in exts)\n",
        "\n",
        "# target = {\n",
        "#     s: count_images(BASE/s/\"chart\")   # Ï∞®Ìä∏ Í∞úÏàòÎßåÌÅº nonchartÎ•º ÎßûÏ∂îÎäî Ï†ÑÎûµ\n",
        "#     for s in SPLITS\n",
        "# }\n",
        "# current = {\n",
        "#     s: count_images(BASE/s/\"nonchart\")\n",
        "#     for s in SPLITS\n",
        "# }\n",
        "# need = { s: max(0, target[s]-current[s]) for s in SPLITS }\n",
        "# print(\"target:\", target, \"\\ncurrent:\", current, \"\\nneed:\", need)\n",
        "\n",
        "# # 2) ÎπÑ-Ïä§Ìä∏Î¶¨Î∞ç Î°úÎìú ‚Üí Î°úÏª¨ Ï∫êÏãúÏóê Ïù¥ÎØ∏ÏßÄ ÌååÏùº ÏÉùÏÑ±\n",
        "# #    (Ìïú Î≤à Î∞õÏïÑÎëêÎ©¥ Ïû¨Ïã§Ìñâ Ïãú Ï∫êÏãú Ïû¨ÏÇ¨Ïö©)\n",
        "# def get_doclaynet_paths(split: str, k: int):\n",
        "#     if k <= 0: return []\n",
        "#     ds = load_dataset(\"ds4sd/DocLayNet-v1.2\", split=split)   # streaming=False (Í∏∞Î≥∏)\n",
        "#     idxs = list(range(min(k, len(ds))))\n",
        "#     random.seed(42); random.shuffle(idxs)                    # ÏïΩÍ∞Ñ ÏÖîÌîå\n",
        "#     paths = []\n",
        "#     for i in idxs:\n",
        "#         im = ds[i][\"image\"]          # PIL Image (datasetsÍ∞Ä Ï∫êÏãú ÌååÏùºÏóêÏÑú Î°úÎìú)\n",
        "#         p  = getattr(im, \"filename\", None)\n",
        "#         if p and os.path.exists(p):  # Ï∫êÏãú ÌååÏùº Í≤ΩÎ°ú ÏûàÏúºÎ©¥ Í∑∏Í±∏ ÏÇ¨Ïö©\n",
        "#             paths.append(p)\n",
        "#         else:\n",
        "#             # ÎìúÎ¨ºÍ≤å filenameÏù¥ ÏóÜÏùÑ Ïàò ÏûàÏùå ‚Üí ÎÇòÏ§ëÏóê saveÎ°ú Ìè¥Î∞± Ï≤òÎ¶¨\n",
        "#             paths.append(im)         # PIL Í∞ùÏ≤¥Î•º Í∑∏ÎåÄÎ°ú Îã¥ÏïÑÎë†\n",
        "#     return paths\n",
        "\n",
        "# # 3) ÎßÅÌÅ¨/Î≥µÏÇ¨/Ï†ÄÏû• Ïú†Ìã∏\n",
        "# def place(paths, out_dir: Path, prefer_symlink=True):\n",
        "#     out_dir.mkdir(parents=True, exist_ok=True)\n",
        "#     ln = cp = sv = 0\n",
        "#     for src in paths:\n",
        "#         if isinstance(src, str):         # Ï∫êÏãú ÌååÏùº Í≤ΩÎ°ú\n",
        "#             dst = out_dir / os.path.basename(src)\n",
        "#             if dst.exists(): continue\n",
        "#             if prefer_symlink:\n",
        "#                 try:\n",
        "#                     os.symlink(src, dst); ln += 1; continue\n",
        "#                 except Exception:\n",
        "#                     pass\n",
        "#             # Ìè¥Î∞±: ÌååÏùº Î≥µÏÇ¨\n",
        "#             import shutil; shutil.copy2(src, dst); cp += 1\n",
        "#         else:\n",
        "#             # PIL.Image Í∞ùÏ≤¥ ‚Üí ÎîîÏä§ÌÅ¨Ïóê Ï†ÄÏû•(Ìè¥Î∞±)\n",
        "#             dst = out_dir / f\"doclaynet_{sv:06d}.png\"\n",
        "#             if dst.exists(): continue\n",
        "#             src.save(dst); sv += 1\n",
        "#     return ln, cp, sv\n",
        "\n",
        "# # 4) Ïã§Ï†ú Î∞∞Ïπò (ÌïÑÏöîÎüâÎßåÌÅº)\n",
        "# for split in SPLITS:\n",
        "#     k = need[split]\n",
        "#     paths = get_doclaynet_paths(split, k)\n",
        "#     ln, cp, sv = place(paths, BASE/split/\"nonchart\", prefer_symlink=True)\n",
        "#     print(f\"{split}: need={k}  -> linked={ln}, copied={cp}, saved={sv}\")\n",
        "\n",
        "# # 5) ÏµúÏ¢Ö Í∞úÏàò ÌôïÏù∏\n",
        "# def count_images(p): \n",
        "#     p = Path(p)\n",
        "#     return sum(1 for x in p.glob(\"*\") if x.suffix.lower() in {\".jpg\",\".jpeg\",\".png\",\".webp\"})\n",
        "# for split in [\"train\",\"val\",\"test\"]:\n",
        "#     print(split, \"chart:\", count_images(f\"data/{split}/chart\"),\n",
        "#                  \"nonchart:\", count_images(f\"data/{split}/nonchart\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## yaml ÌååÏùº ÏÉùÏÑ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1755796202891
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train/chart: 18317 images\n",
            "train/nonchart: 18317 images\n",
            "val/chart: 1056 images\n",
            "val/nonchart: 1056 images\n",
            "test/chart: 1509 images\n",
            "test/nonchart: 1509 images\n",
            "\n",
            "=== data.yaml ===\n",
            "train: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/train\n",
            "val: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/val\n",
            "test: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/test\n",
            "names:\n",
            "  0: chart\n",
            "  1: nonchart\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os, yaml, pathlib\n",
        "\n",
        "DATA_ROOT = \"data\"  # data/{train,val,test}/{chart,nonchart}\n",
        "\n",
        "def real(p):  # symlink ÏïàÏ†ÑÌïòÍ≤å Ï†àÎåÄÍ≤ΩÎ°úÎ°ú Í≥†Ï†ï\n",
        "    return os.path.realpath(p)\n",
        "\n",
        "# sanity check: Í∞Å splitÏóê ÏµúÏÜå 1Ïû•Ïî© Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏\n",
        "def count_imgs(d):\n",
        "    exts = {\".jpg\",\".jpeg\",\".png\",\".webp\"}\n",
        "    d = pathlib.Path(d)\n",
        "    return sum(1 for x in d.glob(\"*\") if x.suffix.lower() in exts)\n",
        "\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    for cls in [\"chart\",\"nonchart\"]:\n",
        "        n = count_imgs(f\"{DATA_ROOT}/{split}/{cls}\")\n",
        "        assert n > 0, f\"[EMPTY] {split}/{cls} ÎπÑÏñ¥ÏûàÏùå. Î®ºÏ†Ä Ï±ÑÏõåÏ£ºÏÑ∏Ïöî.\"\n",
        "        print(f\"{split}/{cls}: {n} images\")\n",
        "\n",
        "data_yaml = {\n",
        "    # Ultralytics Î∂ÑÎ•òÎäî Í∞Å split ÎîîÎ†âÌÜ†Î¶¨ ÌïòÏúÑÏùò Ìè¥ÎçîÎ™ÖÏù¥ ÌÅ¥ÎûòÏä§Í∞Ä Îê®\n",
        "    \"train\": real(f\"{DATA_ROOT}/train\"),\n",
        "    \"val\":   real(f\"{DATA_ROOT}/val\"),\n",
        "    \"test\":  real(f\"{DATA_ROOT}/test\"),\n",
        "\n",
        "    # namesÎäî Î™ÖÏãúÌï¥ÎëêÎ©¥ ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§Í∞Ä Í≥†Ï†ïÎèºÏÑú ÏïàÏ†ÑÌï®(0: chart, 1: nonchart)\n",
        "    \"names\": {0: \"chart\", 1: \"nonchart\"}\n",
        "}\n",
        "\n",
        "pathlib.Path(DATA_ROOT).mkdir(parents=True, exist_ok=True)\n",
        "with open(f\"{DATA_ROOT}/data.yaml\",\"w\") as f:\n",
        "    yaml.safe_dump(data_yaml, f, sort_keys=False, allow_unicode=True)\n",
        "\n",
        "print(\"\\n=== data.yaml ===\")\n",
        "print(open(f\"{DATA_ROOT}/data.yaml\",\"r\").read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# YOLOv11 Î∂ÑÎ•ò ÌïôÏäµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1755798562233
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Train] batch=256, epochs=30, imgsz=224, workers=16\n",
            "New https://pypi.org/project/ultralytics/8.3.183 available üòÉ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.182 üöÄ Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA H100 NVL, 95248MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=256, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=chart_nonchart_cls_y11s_1755796203, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/classify/chart_nonchart_cls_y11s_1755796203, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=16, workspace=None\n",
            "ERROR ‚ùå \u001b[34m\u001b[1mtrain:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/train... found 18317 images in 1 classes (requires 2 classes, not 1)\n",
            "ERROR ‚ùå \u001b[34m\u001b[1mval:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/val... found 1056 images in 1 classes (requires 2 classes, not 1)\n",
            "ERROR ‚ùå \u001b[34m\u001b[1mtest:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/test... found 1509 images in 1 classes (requires 2 classes, not 1)\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 10                  -1  1    660482  ultralytics.nn.modules.head.Classify         [512, 2]                      \n",
            "YOLO11s-cls summary: 86 layers, 5,445,570 parameters, 5,445,570 gradients, 12.1 GFLOPs\n",
            "Transferred 234/236 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "WARNING ‚ö†Ô∏è Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.002), 40 bias(decay=0.0)\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/chart_nonchart_cls_y11s_1755796203\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/train... 18317 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18317/18317 [02:53<00:00, 105.44it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/val... 1056 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1056/1056 [00:10<00:00, 104.68it/s]\n",
            "       1/30      5.36G     0.1124        141        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 72/72 [01:27<00:00,  1.21s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.86it/s]\n",
            "       2/30      6.33G   6.03e-05        141        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 72/72 [01:28<00:00,  1.22s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 57.19it/s]\n",
            "       4/30      6.37G  1.796e-05        256        224:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 54/72 [00:57<00:06,  2.99it/s]"
          ]
        }
      ],
      "source": [
        "# === YOLO11s Classification: train -> val -> test -> export ===\n",
        "# H100 NVL Í∏∞Ï§Ä ÏÑ§Ï†ï. OOM ÎÇòÎ©¥ BATCHÎ•º 256 -> 128 -> 64Î°ú ÎÇÆÏ∂∞ÏÑú Ïû¨ÏãúÎèÑ.\n",
        "\n",
        "import os, glob, json, shutil, pathlib, time\n",
        "from ultralytics import YOLO\n",
        "\n",
        "DATA_YAML = os.path.realpath(\"data\")\n",
        "MODEL     = \"yolo11s-cls.pt\"          # ÏÇ¨Ï†ÑÌïôÏäµ Î™®Îç∏\n",
        "IMGSZ     = 224                       # Î∂ÑÎ•ò Í∏∞Î≥∏ Ìï¥ÏÉÅÎèÑ\n",
        "EPOCHS    = 30                        # Î®ºÏ†Ä 30epoch Ïä§Î™®ÌÅ¨ ‚Üí Í∞úÏÑ† Ïãú 50~100\n",
        "WORKERS   = min(os.cpu_count() or 8, 16)\n",
        "SEED      = 42\n",
        "\n",
        "# H100Ïù¥Î©¥ 256ÎèÑ Ïó¨Ïú†. OOMÏãú 128/64Î°ú ÎÇÆÏ∂∞ Ïû¨Ïã§Ìñâ.\n",
        "BATCH_CANDIDATES = [256, 128, 64]\n",
        "\n",
        "run_name = f\"chart_nonchart_cls_y11s_{int(time.time())}\"\n",
        "\n",
        "def try_train(batch):\n",
        "    print(f\"\\n[Train] batch={batch}, epochs={EPOCHS}, imgsz={IMGSZ}, workers={WORKERS}\")\n",
        "    model = YOLO(MODEL)\n",
        "    res = model.train(\n",
        "        data=DATA_YAML,\n",
        "        epochs=EPOCHS,\n",
        "        imgsz=IMGSZ,\n",
        "        batch=batch,\n",
        "        workers=WORKERS,\n",
        "        name=run_name,\n",
        "        seed=SEED,\n",
        "        cache=True,        # ÎîîÏä§ÌÅ¨ Ï∫êÏãúÎ°ú I/O Ï∂ïÏÜå\n",
        "        amp=True,          # mixed precision\n",
        "        cos_lr=True,       # cosine LR schedule\n",
        "        patience=10,       # early stopping\n",
        "        plots=True,        # ÌïôÏäµ Í≥°ÏÑ†/CM Îì± Ï†ÄÏû•\n",
        "        verbose=True,\n",
        "    )\n",
        "    return model, res\n",
        "\n",
        "trained = None\n",
        "for b in BATCH_CANDIDATES:\n",
        "    try:\n",
        "        model, train_res = try_train(b)\n",
        "        trained = (model, train_res)\n",
        "        break\n",
        "    except RuntimeError as e:\n",
        "        if \"CUDA out of memory\" in str(e):\n",
        "            print(f\"OOM at batch={b}, retrying with smaller batch...\")\n",
        "            continue\n",
        "        raise\n",
        "\n",
        "assert trained is not None, \"Training failed at all batch sizes\"\n",
        "model, train_res = trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Test & Í≤∞Í≥º ÌååÏùº/Î™®Îç∏ Ï†ÄÏû•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Best ModelÎ°ú Test ÏßÑÌñâ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1755798745101
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TEST] using weights: runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.pt\n",
            "Ultralytics 8.3.182 üöÄ Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA H100 NVL, 95248MiB)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
            "ERROR ‚ùå \u001b[34m\u001b[1mtrain:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/train... found 18317 images in 1 classes (requires 2 classes, not 1)\n",
            "ERROR ‚ùå \u001b[34m\u001b[1mval:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/val... found 1056 images in 1 classes (requires 2 classes, not 1)\n",
            "ERROR ‚ùå \u001b[34m\u001b[1mtest:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/test... found 1509 images in 1 classes (requires 2 classes, not 1)\n",
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val\u001b[0m\n",
            "test metrics: {'metrics/accuracy_top1': 1.0, 'metrics/accuracy_top5': 1.0, 'fitness': 1.0}\n",
            "‚úÖ saved: runs/classify/chart_nonchart_cls_y11s_1755796203/summaries/test_summary.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data/test... 1509 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1509/1509 [00:15<00:00, 97.41it/s] \n",
            "               classes   top1_acc   top5_acc:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 69/95 [00:07<00:02, 10.90it/s]"
          ]
        }
      ],
      "source": [
        "# === TEST with best.pt ===\n",
        "import os, glob, json, pathlib\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# 1) ÏµúÏã† run Ìè¥Îçî/Í∞ÄÏ§ëÏπò Ï∞æÍ∏∞\n",
        "runs = sorted(glob.glob(f\"runs/classify/{run_name}*\"), key=os.path.getmtime)\n",
        "assert runs, \"run Ìè¥ÎçîÎ•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§.\"\n",
        "run_dir = pathlib.Path(runs[-1])\n",
        "w_best  = run_dir/\"weights\"/\"best.pt\"\n",
        "w_last  = run_dir/\"weights\"/\"last.pt\"\n",
        "use_w   = w_best if w_best.exists() else w_last\n",
        "assert use_w.exists(), \"best/last Í∞ÄÏ§ëÏπòÍ∞Ä ÏóÜÏäµÎãàÎã§.\"\n",
        "\n",
        "# 2) Best Weight ÏÇ¨Ïö©Ìïú best modelÎ°ú ÌÖåÏä§Ìä∏ ÏßÑÌñâ\n",
        "print(f\"[TEST] using weights: {use_w}\")\n",
        "model_for_test = YOLO(str(use_w))\n",
        "\n",
        "test_res = model_for_test.val(\n",
        "    data=DATA_YAML,\n",
        "    split=\"test\",\n",
        "    imgsz=IMGSZ,\n",
        "    workers=WORKERS,\n",
        ")\n",
        "\n",
        "print(\"test metrics:\", test_res.results_dict)\n",
        "\n",
        "summary_dir = run_dir / \"summaries\"\n",
        "summary_dir.mkdir(parents=True, exist_ok=True)\n",
        "with open(summary_dir / \"test_summary.json\", \"w\") as f:\n",
        "    json.dump({k: float(v) for k, v in test_res.results_dict.items()}, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ saved:\", summary_dir / \"test_summary.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## ÏÇ∞Ï∂úÎ¨º packaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1755799006711
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Packed: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/model_artifact\n"
          ]
        }
      ],
      "source": [
        "import os, json, shutil, glob, pathlib, time\n",
        "from ultralytics import __version__ as ulty_ver\n",
        "\n",
        "# 1) ÏµúÏã† run Ìè¥Îçî/Í∞ÄÏ§ëÏπò Ï∞æÍ∏∞\n",
        "runs = sorted(glob.glob(f\"runs/classify/{run_name}*\"), key=os.path.getmtime)\n",
        "assert runs, \"run Ìè¥ÎçîÎ•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§.\"\n",
        "run_dir = pathlib.Path(runs[-1])\n",
        "w_best  = run_dir/\"weights\"/\"best.pt\"\n",
        "w_last  = run_dir/\"weights\"/\"last.pt\"\n",
        "use_w   = w_best if w_best.exists() else w_last\n",
        "assert use_w.exists(), \"best/last Í∞ÄÏ§ëÏπòÍ∞Ä ÏóÜÏäµÎãàÎã§.\"\n",
        "\n",
        "# 2) ÌÖåÏä§Ìä∏ ÏöîÏïΩ(ÏûàÏúºÎ©¥)ÏôÄ data.yaml Í∞ôÏùÄ Î†àÌçºÎü∞Ïä§ÎèÑ Î¨∂Í∏∞\n",
        "artifact_dir = pathlib.Path(\"model_artifact\")\n",
        "if artifact_dir.exists():\n",
        "    shutil.rmtree(artifact_dir)\n",
        "(artifact_dir/\"weights\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "shutil.copy2(use_w, artifact_dir/\"weights\"/use_w.name)\n",
        "for extra in [\"data/data.yaml\", str(run_dir/\"summaries\"/\"test_summary.json\")]:\n",
        "    p = pathlib.Path(extra)\n",
        "    if p.exists():\n",
        "        dst = artifact_dir/p.name if p.suffix else artifact_dir/p.parts[-1]\n",
        "        try:\n",
        "            shutil.copy2(p, dst)\n",
        "        except IsADirectoryError:\n",
        "            shutil.copytree(p, artifact_dir/p.name, dirs_exist_ok=True)\n",
        "\n",
        "# 3) Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Í∏∞Î°ù(ÏûëÏóÖ Ïû¨ÌòÑÏö©)\n",
        "meta = {\n",
        "    \"task\": \"image-classification\",\n",
        "    \"classes\": {0:\"chart\", 1:\"nonchart\"},\n",
        "    \"imgsz\": 224,\n",
        "    \"epochs\": 30,\n",
        "    \"ultralytics_version\": ulty_ver,\n",
        "    \"source_run\": str(run_dir),\n",
        "    \"weight_file\": use_w.name,\n",
        "}\n",
        "with open(artifact_dir/\"model_card.json\",\"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "print(\"üì¶ Packed:\", artifact_dir.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## ML ÏõåÌÅ¨Ïä§ÌéòÏù¥Ïä§Ïóê Î™®Îç∏ Îì±Î°ù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1755799320709
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding of current TracerProvider is not allowed\n",
            "Overriding of current LoggerProvider is not allowed\n",
            "Overriding of current MeterProvider is not allowed\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "\u001b[32mUploading model_artifact (11.02 MBs): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11024766/11024766 [00:00<00:00, 38302016.46it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Registered model: yolo11-chart-binary-cls v1\n"
          ]
        }
      ],
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import Model\n",
        "\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# .env\n",
        "load_dotenv()\n",
        "\n",
        "# get environment variables\n",
        "sub_id = os.getenv(\"SUBSCRIPTION_ID\")\n",
        "rg = os.getenv(\"RESOURCE_GROUP\")\n",
        "ws_name = os.getenv(\"WORKSPACE_NAME\")\n",
        "\n",
        "# (A) Íµ¨ÎèÖ/Î¶¨ÏÜåÏä§/WSÎ•º ÏßÅÏ†ë ÏßÄÏ†ï\n",
        "SUBSCRIPTION_ID = sub_id\n",
        "RESOURCE_GROUP  = rg\n",
        "WORKSPACE_NAME  = ws_name\n",
        "\n",
        "# (B) ÌòπÏùÄ config.jsonÏù¥ ÎÖ∏Ìä∏Î∂ÅÏóê ÏÑ∏ÌåÖÎêòÏñ¥ ÏûàÎã§Î©¥:\n",
        "# from azure.ai.ml import MLClient\n",
        "# ml_client = MLClient.from_config()\n",
        "\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(),\n",
        "    SUBSCRIPTION_ID,\n",
        "    RESOURCE_GROUP,\n",
        "    WORKSPACE_NAME,\n",
        ")\n",
        "\n",
        "model_name = \"yolo11-chart-binary-cls\"   # ÏõêÌïòÎäî Í≥†Ï†ï Ïù¥Î¶Ñ\n",
        "model = Model(\n",
        "    name=model_name,\n",
        "    path=str(artifact_dir),             # Ìè¥Îçî ÌÜµÏß∏Î°ú ÏóÖÎ°úÎìú\n",
        "    type=\"custom_model\",                # .pt/onnx Î¨∂ÏùåÏù¥Î©¥ custom_model Ï†ÅÌï©\n",
        "    description=\"YOLO11s classification (chart vs nonchart). Includes weights and metadata.\",\n",
        "    tags={\n",
        "        \"task\":\"classification\",\n",
        "        \"backbone\":\"yolo11s-cls\",\n",
        "        \"classes\":\"chart,nonchart\",\n",
        "    },\n",
        "    properties={\n",
        "        \"ultralytics_version\": ulty_ver,\n",
        "        \"imgsz\":\"224\",\n",
        "    }\n",
        ")\n",
        "\n",
        "registered = ml_client.models.create_or_update(model)\n",
        "print(f\"‚úÖ Registered model: {registered.name} v{registered.version}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### (Optional) ONNX/TorchScript ÎÇ¥Î≥¥ÎÇ¥Í∏∞\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1755799511081
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[EXPORT] onnx (fp32)\n",
            "Ultralytics 8.3.182 üöÄ Python-3.12.11 torch-2.8.0+cu128 CPU (AMD EPYC 9V84 96-Core Processor)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 2) (10.5 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<1.18.0', 'onnxslim>=0.1.59', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Requirement already satisfied: onnx<1.18.0,>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.17.0)\n",
            "Collecting onnxslim>=0.1.59\n",
            "  Downloading onnxslim-0.1.64-py3-none-any.whl (164 kB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 164.0/164.0 kB 37.2 MB/s eta 0:00:00\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.22.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (283.2 MB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 283.2/283.2 MB 166.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.20 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnx<1.18.0,>=1.12.0) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnx<1.18.0,>=1.12.0) (4.25.8)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnxslim>=0.1.59) (1.13.3)\n",
            "Requirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnxslim>=0.1.59) (25.0)\n",
            "Requirement already satisfied: colorama in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnxslim>=0.1.59) (0.4.6)\n",
            "Requirement already satisfied: coloredlogs in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnxruntime-gpu) (25.2.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sympy>=1.13.3->onnxslim>=0.1.59) (1.3.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "Installing collected packages: onnxslim, onnxruntime-gpu\n",
            "Successfully installed onnxruntime-gpu-1.22.0 onnxslim-0.1.64\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 11.5s\n",
            "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 19...\n",
            "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: No module named 'onnxslim'\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 12.8s, saved as 'runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.onnx' (20.8 MB)\n",
            "\n",
            "Export complete (13.0s)\n",
            "Results saved to \u001b[1m/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/runs/classify/chart_nonchart_cls_y11s_1755796203/weights\u001b[0m\n",
            "Predict:         yolo predict task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.onnx imgsz=224  \n",
            "Validate:        yolo val task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.onnx imgsz=224 data=/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data  \n",
            "Visualize:       https://netron.app\n",
            "[EXPORT] torchscript\n",
            "Ultralytics 8.3.182 üöÄ Python-3.12.11 torch-2.8.0+cu128 CPU (AMD EPYC 9V84 96-Core Processor)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 2) (10.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.8.0+cu128...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ‚úÖ 0.7s, saved as 'runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.torchscript' (20.9 MB)\n",
            "\n",
            "Export complete (0.9s)\n",
            "Results saved to \u001b[1m/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/runs/classify/chart_nonchart_cls_y11s_1755796203/weights\u001b[0m\n",
            "Predict:         yolo predict task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.torchscript imgsz=224  \n",
            "Validate:        yolo val task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.torchscript imgsz=224 data=/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data  \n",
            "Visualize:       https://netron.app\n",
            "\n",
            "Done. Exported Artifacts in: runs/classify/chart_nonchart_cls_y11s_1755796203\n"
          ]
        }
      ],
      "source": [
        "best_model = YOLO(str(use_w))\n",
        "print(\"\\n[EXPORT] onnx (fp32)\")\n",
        "best_model.export(format=\"onnx\", imgsz=IMGSZ)\n",
        "print(\"[EXPORT] torchscript\")\n",
        "best_model.export(format=\"torchscript\", imgsz=IMGSZ)\n",
        "\n",
        "print(\"\\nDone. Exported Artifacts in:\", run_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "ONNX: starting export with onnx 1.18.0 opset 19...\n",
        "WARNING ‚ö†Ô∏è ONNX: simplifier failure: No module named 'onnxslim'\n",
        "ONNX: export success ‚úÖ 12.8s, saved as 'runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.onnx' (20.8 MB)\n",
        "\n",
        "Export complete (13.0s)\n",
        "Results saved to /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/runs/classify/chart_nonchart_cls_y11s_1755796203/weights\n",
        "Predict:         yolo predict task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.onnx imgsz=224  \n",
        "Validate:        yolo val task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.onnx imgsz=224 data=/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data  \n",
        "Visualize:       https://netron.app\n",
        "[EXPORT] torchscript\n",
        "Ultralytics 8.3.182 üöÄ Python-3.12.11 torch-2.8.0+cu128 CPU (AMD EPYC 9V84 96-Core Processor)\n",
        "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
        "\n",
        "PyTorch: starting from 'runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 2) (10.5 MB)\n",
        "\n",
        "TorchScript: starting export with torch 2.8.0+cu128...\n",
        "TorchScript: export success ‚úÖ 0.7s, saved as 'runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.torchscript' (20.9 MB)\n",
        "\n",
        "Export complete (0.9s)\n",
        "Results saved to /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/runs/classify/chart_nonchart_cls_y11s_1755796203/weights\n",
        "Predict:         yolo predict task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.torchscript imgsz=224  \n",
        "Validate:        yolo val task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.torchscript imgsz=224 data=/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data  \n",
        "Visualize:       https://netron.app\n",
        "\n",
        "Done. Exported Artifacts in: runs/classify/chart_nonchart_cls_y11s_1755796203\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "yolo11env"
    },
    "kernelspec": {
      "display_name": "Python (yolo11env)",
      "language": "python",
      "name": "yolo11env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
